{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as k\n",
    "import sklearn as sk\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_train = np.reshape(np.loadtxt('../../bindigit_trn.csv', delimiter=',', dtype = 'float32'), [8000, 784])\n",
    "bd_test = np.reshape(np.loadtxt('../../bindigit_tst.csv', delimiter=',', dtype = 'float32'), [2000, 784])\n",
    "td_train = np.reshape(np.loadtxt('../../targetdigit_trn.csv', delimiter=',', dtype = 'float32'), [8000])\n",
    "td_test = np.reshape(np.loadtxt('../../targetdigit_tst.csv', delimiter=',', dtype = 'float32'), [2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model_1_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_list = [100]\n",
    "reg = 0.01\n",
    "batch_size = 100\n",
    "epochs = 150\n",
    "\n",
    "# Pretraining layer 1\n",
    "model = k.models.Sequential()\n",
    "model.add(k.layers.Dense(n_hidden_list[0], input_dim = 784, kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model.add(k.layers.Dense(784, kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(bd_train, bd_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "weights1 = model.get_weights()[0:2]\n",
    "\n",
    "model.pop()\n",
    "values_model = model.predict(bd_train)\n",
    "\n",
    "# Classification layer\n",
    "\n",
    "model4 = k.models.Sequential()\n",
    "model4.add(k.layers.Dense(units=1, input_dim = n_hidden_list[0], kernel_initializer='RandomNormal', activation='relu', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model4.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model4.fit(values_model, td_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "values_model4 = model4.predict(values_model)\n",
    "\n",
    "input1 = k.Input(shape=[784])\n",
    "output1 = model(input1)\n",
    "output4 = model4(output1)\n",
    "model_3_hidden_layer = k.models.Model(input1,output4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model_2_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_list = [100,80]\n",
    "reg = 0.01\n",
    "batch_size = 100\n",
    "epochs = 150\n",
    "\n",
    "# Pretraining layer 1\n",
    "model = k.models.Sequential()\n",
    "model.add(k.layers.Dense(n_hidden_list[0], input_dim = 784, kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model.add(k.layers.Dense(784, kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(bd_train, bd_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "weights1 = model.get_weights()[0:2]\n",
    "\n",
    "model.pop()\n",
    "values_model = model.predict(bd_train)\n",
    "\n",
    "# Pretraining layer 2\n",
    "\n",
    "model2 = k.models.Sequential()\n",
    "model2.add(k.layers.Dense(n_hidden_list[1], input_dim = n_hidden_list[0], kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model2.add(k.layers.Dense(784, kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model2.fit(values_model, bd_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "model2.pop()\n",
    "values_model2 = model2.predict(values_model)\n",
    "\n",
    "# Classification layer\n",
    "\n",
    "model4 = k.models.Sequential()\n",
    "model4.add(k.layers.Dense(units=1, input_dim = n_hidden_list[1], kernel_initializer='RandomNormal', activation='relu', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model4.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model4.fit(values_model2, td_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "values_model4 = model4.predict(values_model2)\n",
    "\n",
    "input1 = k.Input(shape=[784])\n",
    "output1 = model(input1)\n",
    "output2 = model2(output1)\n",
    "output4 = model4(output2)\n",
    "model_3_hidden_layer = k.models.Model(input1,output4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model_3_hidden_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_list = [100,80,60]\n",
    "reg = 0.01\n",
    "batch_size = 100\n",
    "epochs = 150\n",
    "\n",
    "# Pretraining layer 1\n",
    "model = k.models.Sequential()\n",
    "model.add(k.layers.Dense(n_hidden_list[0], input_dim = 784, kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model.add(k.layers.Dense(784, kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(bd_train, bd_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "weights1 = model.get_weights()[0:2]\n",
    "\n",
    "model.pop()\n",
    "values_model = model.predict(bd_train)\n",
    "\n",
    "# Pretraining layer 2\n",
    "\n",
    "model2 = k.models.Sequential()\n",
    "model2.add(k.layers.Dense(n_hidden_list[1], input_dim = n_hidden_list[0], kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model2.add(k.layers.Dense(784, kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model2.fit(values_model, bd_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "model2.pop()\n",
    "values_model2 = model2.predict(values_model)\n",
    "\n",
    "# Pretraining layer 3\n",
    "\n",
    "model3 = k.models.Sequential()\n",
    "model3.add(k.layers.Dense(n_hidden_list[2], input_dim = n_hidden_list[1], kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model3.add(k.layers.Dense(784, kernel_initializer='RandomNormal', activation='sigmoid', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model3.fit(values_model2, bd_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "model3.pop()\n",
    "values_model3 = model3.predict(values_model2)\n",
    "\n",
    "# Classification layer\n",
    "\n",
    "model4 = k.models.Sequential()\n",
    "model4.add(k.layers.Dense(units=1, input_dim = n_hidden_list[2], kernel_initializer='RandomNormal', activation='relu', use_bias = True,\n",
    "                             bias_initializer = 'Zeros', kernel_regularizer=k.regularizers.l2(reg)))\n",
    "model4.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model4.fit(values_model3, td_train, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "values_model4 = model4.predict(values_model3)\n",
    "\n",
    "input1 = k.Input(shape=[784])\n",
    "output1 = model(input1)\n",
    "output2 = model2(output1)\n",
    "output3 = model3(output2)\n",
    "output4 = model4(output3)\n",
    "model_3_hidden_layer = k.models.Model(input1,output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x23caf38d908>,\n",
       " <keras.engine.sequential.Sequential at 0x23cafdf99b0>,\n",
       " <keras.engine.sequential.Sequential at 0x23cafdf9fd0>,\n",
       " <keras.engine.sequential.Sequential at 0x23cafdfe710>,\n",
       " <keras.engine.sequential.Sequential at 0x23caff597f0>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-9.58469900e-06, -2.94784368e-05, -1.51686504e-06, ...,\n",
       "          6.23148226e-05, -7.99518239e-06,  1.36721865e-05],\n",
       "        [-2.26663064e-06, -2.49823233e-06,  5.54994926e-07, ...,\n",
       "          4.25550979e-06, -1.30767603e-06,  4.18842956e-06],\n",
       "        [-4.81963252e-06,  7.02804027e-06,  1.34461116e-05, ...,\n",
       "          4.98332520e-06, -1.53517449e-05,  3.55695329e-06],\n",
       "        ...,\n",
       "        [-3.13914788e-05, -1.31989127e-05, -3.13104010e-07, ...,\n",
       "         -1.41160799e-05, -3.77100378e-06, -2.65245967e-06],\n",
       "        [ 2.08652136e-06,  8.50433717e-05, -1.34115374e-09, ...,\n",
       "         -1.72630234e-06, -4.80588551e-06,  9.20361435e-06],\n",
       "        [-3.10868927e-06,  4.42843884e-07,  7.99754525e-06, ...,\n",
       "          2.15147193e-05, -2.53528469e-08,  9.77693617e-06]], dtype=float32),\n",
       " array([0.46073544, 0.5118697 , 0.51019204, 0.5039512 , 0.51470184,\n",
       "        0.50429535, 0.53685486, 0.51562834, 0.48534146, 0.5161413 ,\n",
       "        0.45061755, 0.54028195, 0.4638092 , 0.4903971 , 0.45855755,\n",
       "        0.4668465 , 0.39380673, 0.5487746 , 0.39024395, 0.46440074,\n",
       "        0.4811399 , 0.48337004, 0.49618754, 0.50071675, 0.45539194,\n",
       "        0.4637457 , 0.4412136 , 0.50587577, 0.49611825, 0.5015677 ,\n",
       "        0.51991343, 0.49387723, 0.4863689 , 0.4827969 , 0.45258027,\n",
       "        0.53639007, 0.5429131 , 0.5164088 , 0.530041  , 0.5304761 ,\n",
       "        0.5281051 , 0.5051909 , 0.52385086, 0.33195356, 0.47332767,\n",
       "        0.41740936, 0.44462332, 0.4965025 , 0.4711834 , 0.44789055,\n",
       "        0.5364414 , 0.5472302 , 0.51002765, 0.55559665, 0.4670482 ,\n",
       "        0.5514421 , 0.51898724, 0.5058595 , 0.558289  , 0.38942736,\n",
       "        0.44223034, 0.49252212, 0.47996688, 0.53898764, 0.4774143 ,\n",
       "        0.5125201 , 0.49202582, 0.5122112 , 0.53743494, 0.526801  ,\n",
       "        0.5279828 , 0.52003765, 0.52038574, 0.47680247, 0.5244323 ,\n",
       "        0.5624529 , 0.53606915, 0.5085763 , 0.47638786, 0.5541439 ,\n",
       "        0.47994328, 0.53805447, 0.5302679 , 0.5426224 , 0.54239994,\n",
       "        0.40852636, 0.51101434, 0.55381095, 0.518398  , 0.43165246,\n",
       "        0.5107874 , 0.46239865, 0.44892013, 0.40765035, 0.5221562 ,\n",
       "        0.4302602 , 0.5029955 , 0.57842857, 0.43876603, 0.4654447 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
